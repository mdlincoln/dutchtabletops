---
title: "Form and Content in 17th-Century Haarlem Still Lifes"
author: "Matthew Lincoln"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Form and Content in 17th-Century Haarlem Still Lifes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r libraries, include = FALSE}
library(dutchtabletopsdata)
library(purrr)
library(dplyr)
library(tidyr)
library(tibble)
library(ggplot2)
library(ggrepel)
library(randomForest)
knitr::opts_chunk$set(fig.width = 9, fig.height = 9, warning = FALSE, echo = FALSE, cache = TRUE)
```

## What are random forests? Why use them?

Random forests are an example of an _ensemble machine learning method_ that works by running many iterations of the same type of model and combining their results in an effort to avoid overfitting.
The core model of random forests are, appropriately, decision trees.
A single decision tree works by finding a split in one of the _predictor variables_ (say, all horizontal paintings over here, all horiztonal ones over here) that does the best job at sorting out paintings based on the given _repsonse variable_ (e.g., which artist painted it.), techinically known as asessing its _node purity_.
One variable split likely does a mediocre job of predicting the response variable, thus the process is repeated, finding the best variable splits for each one of the branches produced by the first split, then the best splits for all the brances produced by that step, and so forth.
Single decision trees can keep producing branches until they have perfectly memorized the data.
Much like an undergraduate who aces the slide ID portion of the art history exam, but bombs the unknown image section, a single tree will perfectly reproduce the data you give it, but does poorly when given new cases that might have slightly different attributes than those it learned from.

Random forests work by creating hundreds or thousands of decision trees, giving each a slightly different subset of the original data to learn. Then, having built each of these trees, the model polls this "forest" in order to classify new data into different categories.
In the case of a model learning to recognize artists based on the motifs used in paintings, some paintings may elicit an overwhelmingly lopsided decision by the forest when it is particularly sure of which attribution to give.
Other paintings, however, may provoke more confusion - their attribution, in other words, may not be supportable based on motif information _alone_.

Random forests are particularly appropriate for our use for several reasons:

1. They work relatively well on small samples of data that have a large number of descriptive variables
1. Random forests performs well on systems where there are complex interactions between variables (e.g., lemon plus wine but _without_ oysters tends to be a painitng by...)

## Building the random forests

There are three main parameters to any of these models:

1. Predictor variables: what variables will the model use to make that prediction?
  1. Motif variables only
  1. Composition variables only
    - With dimension informaion? Without?
  1. All available variables
1. Response variable: what categorical or scalar value are we attempting to predict?
  1. An unqualified artist attribution (e.g "Pieter Claesz")
  1. A qualified attribution ("after Pieter Claesz", "possibly Pieter Claesz")
  1. Some other variable, e.g. general compositional scheme
1. Data subset: What subset of the available observations (in this case, paintings) will the model use to make predictions? Just those paintings with definitve attributions? All available paintings? Paintings from a given period of time?

Because we may be interested in any number of combinations of these three parameters, we'll produce random forests for every combination up front, allowing easier exploration on the back end.

```{r model_specs, message=FALSE}
# Model artists with only n or more paintings
n_ptg <- 5
cleared_artists <- unique(filter(group_by(dt_compiled, artist), n() >= n_ptg)$artist)
cleared_artist_union <- unique(filter(group_by(dt_compiled, artist_union), n() >= n_ptg)$artist_union)

dt_valid <- dt_compiled %>% 
  filter(artist %in% cleared_artists, artist_union %in% cleared_artist_union)

# Model specifications
model_predictors <- list(
  motif_only = motif_vars(),
  composition_only = comp_vars()
  # comp_nodim = setdiff(comp_vars(), c("height", "width")),
  # combined = c(motif_vars(), comp_vars())
)

model_response <- list(
  simple = "artist",
  # qualified = "artist_union",
  comp_disp = "compositional_disposition",
  year = "year_early"
)

model_subsets <- list(
  definite_only = which(dt_valid$artist_relationship == "Definite" & dt_valid$artist_union %in% cleared_artist_union & dt_valid$artist %in% cleared_artists)
)

model_tests <- list(
  qualified_only = which(dt_valid$artist_relationship != "Definite" & dt_valid$artist_union %in% cleared_artist_union & dt_valid$artist %in% cleared_artists)
)

# Produce all combinations (the dot product) of these three model parameters
model_params <- list(
  predictors = model_predictors, 
  response = model_response, 
  subsets = model_subsets, 
  tests = model_tests) %>% 
  cross_named_lists()

# Actually run the models
rfl <- map(model_params, function(x) run_rf(dt_valid, response = x$response, predictors = x$predictors, ntree = 5000, portion = x$subsets, test = x$tests))

# Add the resulting random forest type ("classification" or "regression") to the
# model name
names(rfl) <- map2_chr(rfl, names(rfl), function(x, y) {
  type <- x$type
  paste(y, type, sep = ".")
})
```

## Which artists were predictable by their chosen motifs? Their chosen compositions?

One core question: are certain artists more or less predictable by the motifs they choose, and/or by the compositions they use to arrange those motifs?

```{r class_errors}
# Produce a long table of model error: how often was a given model "wrong" about
# the category in which it placed an artwork?
rfl_df <- rfl %>% 
  keep(function(x) x$type == "classification") %>% 
  map_df(error_only, .id = "model_type") %>% 
  separate(model_type, into = c("predictors", "response", "subset", "test", "forest_type"), sep = "\\.")
```

```{r plot_errors}
per_artist_error <- rfl_df %>% 
  filter(response == "simple" & subset == "definite_only" & predictors %in% c("motif_only", "composition_only")) %>% 
  select(-subset, -response, -forest_type, -test) %>% 
  ungroup() %>% 
  spread(predictors, class.error) %>% 
  rename(artist = actual) %>% 
  mutate(
    artist_relationship = factor("Definite", levels = c("Definite", "Possible", "After")),
    artist = factor(artist, levels = sort(unique(artist))))

pae <- ggplot(per_artist_error, aes(x = composition_only, y = motif_only, color = artist, shape = artist_relationship)) +
  theme_error(xname = "Composition", yname = "Motif") +
  geom_point(size = 5) +
  geom_label_repel(aes(label = artist))

multiplot(pae, height = 7.5, width = 10)
```

Several points of note:

1. Gerrit Heda is a mercurial painter: of the "Definite" attributions, the model is mistaken more that 75% of the time when trying to attribute them on either motif or compositional predictors.
1. The other painters are relatively more predictable, though Cornelis Mahu's compositional variety means the model mistakes his works for others almost half the time. 
  1. Pieter Claesz apparently has an exceptionally stable set of motifs - 9 out of 10 times the model can accurate predict his works based on motif information alone.
  2. Floris van Dijck has compositions that are almost just as predictable.

Things get complex when looking at the difference between unqualified Willem Claesz Heda and Pieter Claesz attributions, and those attributions that are "after" the style of WCH or PC.


```{r display_test}
known_only_motif <- rfl$motif_only.simple.definite_only.qualified_only.classification
known_only_comp <- rfl$composition_only.simple.definite_only.qualified_only.classification

test_votes <- function(model) {
  
  votes <- model$test$votes
  
  stopifnot(!is.null(votes))
  
  votes %>% 
    as.data.frame() %>% 
    rownames_to_column("painting_code") %>% 
  inner_join(select(dt_compiled, painting_code, artist, artist_relationship), by = "painting_code") %>% 
  gather(predicted, ratio, -painting_code, -artist, -artist_relationship) %>% 
  group_by(painting_code, artist, artist_relationship) %>% 
  filter(min_rank(desc(ratio)) == 1) %>% 
  ungroup() %>% 
  select(-ratio) %>% 
  mutate(correct = artist == predicted) %>% 
  group_by(artist, artist_relationship) %>% 
  summarize(error = 1 - mean(correct))
}

test_errors <- bind_rows(
  motif_only = test_votes(known_only_motif),
  composition_only = test_votes(known_only_comp),
  .id = "type") %>% 
  spread(type, error) %>% 
  ungroup() %>% 
  filter(artist_relationship != "Co-painter")

all_error <- bind_rows(
  old = per_artist_error, 
  new = test_errors) %>% 
  mutate(
    artist = factor(artist, levels = sort(unique(artist))),
    artist_relationship = factor(artist_relationship, c("Definite", "Possible", "After")))

all_quals_error <- ggplot(all_error, aes(x = composition_only, y = motif_only, color = artist, shape = artist_relationship, alpha = artist_relationship != "Definite")) +
  theme_error("Composition", "Motif") +
  geom_point(size = 5) +
  scale_alpha_discrete(c(1, 0.1), guide = FALSE) +
  geom_label_repel(aes(label = artist))

multiplot(all_quals_error, height = 7, width = 10)
```


## Local variable importance

It is also possible

```{r pca, fig.width=4, fig.height=4}
single_rf <- rfl$motif_only.simple.definite_only.qualified_only.classification

rfl_pca <- map(set_names(levels(single_rf$predicted)), function(x) {
  rf_local_importance(single_rf) %>% 
    semi_join(dt_compiled %>% filter(artist == x[1]), by = c("rowname" = "painting_code")) %>% 
    column_to_rownames("rowname") %>% 
    prcomp()
})

join_loadings <- function(pca) {
  pca_loadings_df(pca) %>% 
    left_join(dt_motif_labels, by = c("rowname" = "motif_code")) %>% 
    mutate(varlab = ifelse(is.na(wrapped_motif_label), rowname, motif_label))
}

rfl_loadings <- map(rfl_pca, join_loadings)

rfl_observations <- map(rfl_pca, pca_obs_df)


artist_motif_plot <- function(l, o, m = 12, hue = "red") {
  l %>% 
    filter(min_rank(desc(power)) <= m) %>% 
    ggplot(aes(x = PC1, y = PC2)) +
    geom_text(data = o, aes(label = rownames), alpha = 0.5) +
    geom_segment(aes(xend = 0, yend = 0), color = hue) +
    geom_label_repel(aes(label = varlab))
}

rfl_plots <- map2(rfl_loadings, rfl_observations, artist_motif_plot) %>% 
  map2(., names(rfl_observations), function(x, y) x + ggtitle(y))

walk2(rfl_plots, seq_len(length(rfl_plots)), function(rfl_plot, y) multiplot(p = rfl_plot, postfix = y, height = 7, width = 10))
```

## Painting dates

```{r rf_date}
library(randomForestCI)

motif_date <- rfl$motif_only.year.definite_only.qualified_only.regression
comp_date <- rfl$composition_only.year.definite_only.qualified_only.regression
motif_date_ci <- randomForestInfJack(comp_date, rf_x(comp_date)) %>% 
  rownames_to_column(var = "painting_code")

rf_resid <- function(rf) {
  stopifnot(rf$type == "regression")
  
  rn <- rf_rownames(rf)
  
  ci <- randomForestInfJack(rf, newdata = rf_x(rf)) %>% 
    rownames_to_column(var = rn)
  
  data.frame(predicted = rf$predicted) %>% 
    rownames_to_column(var = rn) %>% 
    inner_join(select(dt_valid, one_of(c(rn, rf_response(rf), "artist"))), by = rn) %>% 
    inner_join(ci, by = rn) %>% 
    mutate(
      resid = log(year_early) - predicted,
      resid_hat = log(year_early) - y.hat)
}



resid <- data.frame(predicted = comp_date$predicted) %>% 
  rownames_to_column(var = "painting_code") %>% 
  inner_join(select(dt_compiled, painting_code, year_early, artist), by = "painting_code") %>% 
  inner_join(motif_date_ci, by = "painting_code") %>% 
  mutate(
    resid = year_early - predicted,
    resid_hat = year_early - y.hat)

ggplot(resid, aes(x = year_early, color = artist)) +
  geom_hline(yintercept = 0) +
  geom_point(aes(y = resid_hat)) +
  scale_color_brewer(type = "qual") +
  geom_errorbar(aes(ymin = resid - var.hat, ymax = resid + var.hat), alpha = 0.3)
```


```{r}

log_date <- run_rf(data = mutate(dt_valid, year_early = sqrt(year_early)), response = "year_early", predictors = motif_vars(), rownames = "painting_code", portion = which(dt_valid$artist_relationship == "Definite"), tests = which(dt_valid$artist_relationship != "Definite"))

log_resid <- rf_resid(log_date)

ggplot(log_resid, aes(x = year_early, y = resid_hat)) + 
  geom_point()

log_resid %>% 
  arrange(resid) %>% 
  mutate(ith = cumsum(resid), ln = row_number()) %>% 
  ggplot(aes(x = ln, y = ith)) +
  geom_point()
```

